# SDK æ–¹æ³•å¯¹æ¯”ï¼šåç«¯æä¾›çš„ vs é¡¹ç›®éœ€è¦çš„

## ğŸ“‹ åç«¯å·²æä¾›çš„æ–¹æ³•ï¼ˆtest_long_generation.cï¼‰

ä» `test_long_generation.c` æ–‡ä»¶ä¸­ï¼Œåç«¯ SDK æä¾›äº†ä»¥ä¸‹æ–¹æ³•ï¼š

1. **`gpuf_init()`** - åˆå§‹åŒ– SDK
2. **`gpuf_cleanup()`** - æ¸…ç† SDK
3. **`gpuf_load_model(model_path)`** - åŠ è½½æ¨¡å‹
4. **`gpuf_create_context(model)`** - åˆ›å»ºä¸Šä¸‹æ–‡
5. **`gpuf_generate_with_sampling(...)`** - ç”Ÿæˆæ–‡æœ¬ï¼ˆå¸¦é‡‡æ ·å‚æ•°ï¼‰

## ğŸ” é¡¹ç›®ä¸­ä½¿ç”¨çš„ @pocketpalai/llama.rn æ–¹æ³•

### 1. åˆå§‹åŒ–ç›¸å…³

#### `initLlama(params, progressCallback)`
- **ä½ç½®ï¼š** `src/store/ModelStore.ts:1099`
- **ç”¨é€”ï¼š** åˆå§‹åŒ– Llama ä¸Šä¸‹æ–‡
- **å‚æ•°ï¼š**
  ```typescript
  {
    model: string,           // æ¨¡å‹è·¯å¾„
    n_ctx: number,          // ä¸Šä¸‹æ–‡çª—å£å¤§å°
    n_batch: number,        // æ‰¹å¤„ç†å¤§å°
    n_ubatch: number,       // æœªæ‰¹å¤„ç†å¤§å°
    n_threads: number,      // çº¿ç¨‹æ•°
    flash_attn: boolean,    // Flash Attention
    cache_type_k: string,  // K ç¼“å­˜ç±»å‹
    cache_type_v: string,  // V ç¼“å­˜ç±»å‹
    n_gpu_layers: number,   // GPU å±‚æ•°
    no_gpu_devices: boolean,// ç¦ç”¨ GPU
    use_mlock: boolean,      // å†…å­˜é”å®š
    use_mmap: boolean,      // å†…å­˜æ˜ å°„
    use_progress_callback: boolean
  }
  ```
- **è¿”å›ï¼š** `Promise<LlamaContext>`
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** `gpuf_load_model` + `gpuf_create_context`ï¼ˆéœ€è¦åˆå¹¶ï¼‰

#### `loadLlamaModelInfo(modelPath)`
- **ä½ç½®ï¼š** `src/utils/memorySettings.ts:25`
- **ç”¨é€”ï¼š** åŠ è½½æ¨¡å‹ä¿¡æ¯ï¼ˆä¸åŠ è½½å®Œæ•´æ¨¡å‹ï¼‰
- **å‚æ•°ï¼š** `modelPath: string`
- **è¿”å›ï¼š** `Promise<ModelInfo>`ï¼ˆåŒ…å«æ–‡ä»¶ç±»å‹ã€å‚æ•°ç­‰ï¼‰
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** âŒ **ç¼ºå¤±** - éœ€è¦æä¾› `gpuf_get_model_info(model_path)`

### 2. LlamaContext å®ä¾‹æ–¹æ³•

#### `context.completion(params, onToken)`
- **ä½ç½®ï¼š** å¤šå¤„ä½¿ç”¨ï¼ˆ`src/hooks/useChatSession.ts:360`, `src/store/ModelStore.ts:2168` ç­‰ï¼‰
- **ç”¨é€”ï¼š** ç”Ÿæˆæ–‡æœ¬ï¼ˆä¸»è¦æ¨ç†æ–¹æ³•ï¼‰
- **å‚æ•°ï¼š**
  ```typescript
  {
    messages: Array<{role: string, content: string | Array}>,
    prompt?: string,
    n_predict: number,        // æœ€å¤§ç”Ÿæˆ token æ•°
    temperature: number,      // æ¸©åº¦
    top_k: number,           // Top-K
    top_p: number,           // Top-P
    min_p: number,           // Min-P
    repeat_penalty: number,  // é‡å¤æƒ©ç½š
    stop: string[],          // åœæ­¢è¯
    response_format?: {      // ç»“æ„åŒ–è¾“å‡º
      type: 'json_schema',
      json_schema: {...}
    },
    // ... æ›´å¤šå‚æ•°
  }
  ```
- **å›è°ƒï¼š** `onToken?: (data: TokenData) => void` - æµå¼è¾“å‡º token
- **è¿”å›ï¼š** `Promise<{text: string, timings: {...}}>`
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** `gpuf_generate_with_sampling`ï¼ˆä½†éœ€è¦æ”¯æŒæ›´å¤šå‚æ•°å’Œæµå¼è¾“å‡ºï¼‰

#### `context.stopCompletion()`
- **ä½ç½®ï¼š** `src/hooks/useChatSession.ts:470`, `src/hooks/useStructuredOutput.ts:45`
- **ç”¨é€”ï¼š** åœæ­¢æ­£åœ¨è¿›è¡Œçš„ç”Ÿæˆ
- **å‚æ•°ï¼š** æ— 
- **è¿”å›ï¼š** `Promise<void>`
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** âŒ **ç¼ºå¤±** - éœ€è¦æä¾› `gpuf_stop_generation(context)`

#### `context.getFormattedChat(messages)`
- **ä½ç½®ï¼š** `src/utils/chat.ts:112`, `src/screens/DevToolsScreen/.../TestCompletionScreen.tsx:324`
- **ç”¨é€”ï¼š** ä½¿ç”¨èŠå¤©æ¨¡æ¿æ ¼å¼åŒ–æ¶ˆæ¯
- **å‚æ•°ï¼š** `messages: ChatMessage[]`
- **è¿”å›ï¼š** `Promise<string | JinjaFormattedChatResult>`
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** âŒ **ç¼ºå¤±** - éœ€è¦æä¾› `gpuf_format_chat(context, messages, template?)`

#### `context.initMultimodal(params)`
- **ä½ç½®ï¼š** `src/store/ModelStore.ts:1123`
- **ç”¨é€”ï¼š** åˆå§‹åŒ–å¤šæ¨¡æ€æ”¯æŒï¼ˆå›¾åƒç†è§£ï¼‰
- **å‚æ•°ï¼š**
  ```typescript
  {
    path: string,      // mmproj æ–‡ä»¶è·¯å¾„
    use_gpu: boolean  // æ˜¯å¦ä½¿ç”¨ GPU
  }
  ```
- **è¿”å›ï¼š** `Promise<boolean>`
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** âŒ **ç¼ºå¤±** - éœ€è¦æä¾› `gpuf_init_multimodal(context, mmproj_path, use_gpu)`

#### `context.isMultimodalEnabled()`
- **ä½ç½®ï¼š** `src/store/ModelStore.ts:1133`, `src/store/ModelStore.ts:1705`
- **ç”¨é€”ï¼š** æ£€æŸ¥å¤šæ¨¡æ€æ˜¯å¦å·²å¯ç”¨
- **å‚æ•°ï¼š** æ— 
- **è¿”å›ï¼š** `Promise<boolean>`
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** âŒ **ç¼ºå¤±** - éœ€è¦æä¾› `gpuf_is_multimodal_enabled(context)`

#### `context.releaseMultimodal()`
- **ä½ç½®ï¼š** `src/store/ModelStore.ts:1186`
- **ç”¨é€”ï¼š** é‡Šæ”¾å¤šæ¨¡æ€èµ„æº
- **å‚æ•°ï¼š** æ— 
- **è¿”å›ï¼š** `Promise<void>`
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** âŒ **ç¼ºå¤±** - éœ€è¦æä¾› `gpuf_release_multimodal(context)`

#### `context.release()`
- **ä½ç½®ï¼š** `src/store/ModelStore.ts:1204`
- **ç”¨é€”ï¼š** é‡Šæ”¾ä¸Šä¸‹æ–‡èµ„æº
- **å‚æ•°ï¼š** æ— 
- **è¿”å›ï¼š** `Promise<void>`
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** âŒ **ç¼ºå¤±** - éœ€è¦æä¾› `gpuf_release_context(context)`

#### `context.bench(pp, tg, pl, nr)`
- **ä½ç½®ï¼š** `src/screens/BenchmarkScreen/BenchmarkScreen.tsx:165`
- **ç”¨é€”ï¼š** è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
- **å‚æ•°ï¼š**
  ```typescript
  pp: number,  // prompt processing
  tg: number,  // token generation
  pl: number,  // prompt length
  nr: number   // number of runs
  ```
- **è¿”å›ï¼š** `Promise<{speedPp: number, speedTg: number}>`
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** âŒ **ç¼ºå¤±** - éœ€è¦æä¾› `gpuf_bench(context, pp, tg, pl, nr)`

#### `context.saveSession(path, size)`
- **ä½ç½®ï¼š** `ios/PocketPal/AppIntents/LlamaInferenceEngine.swift:339`
- **ç”¨é€”ï¼š** ä¿å­˜ä¼šè¯ç¼“å­˜
- **å‚æ•°ï¼š**
  ```typescript
  path: string,  // ä¿å­˜è·¯å¾„
  size: number   // ä¿å­˜çš„ token æ•°é‡ï¼ˆ-1 è¡¨ç¤ºå…¨éƒ¨ï¼‰
  ```
- **è¿”å›ï¼š** `Promise<number>` - ä¿å­˜çš„ token æ•°é‡
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** âŒ **ç¼ºå¤±** - éœ€è¦æä¾› `gpuf_save_session(context, path, size)`

#### `context.loadSession(path)`
- **ä½ç½®ï¼š** `ios/PocketPal/AppIntents/LlamaContextWrapper.mm:116`
- **ç”¨é€”ï¼š** åŠ è½½ä¼šè¯ç¼“å­˜
- **å‚æ•°ï¼š** `path: string`
- **è¿”å›ï¼š** `Promise<SessionData>`
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** âŒ **ç¼ºå¤±** - éœ€è¦æä¾› `gpuf_load_session(context, path)`

#### `context.invalidate()`
- **ä½ç½®ï¼š** `ios/PocketPal/AppIntents/LlamaInferenceEngine.swift:318`
- **ç”¨é€”ï¼š** ä½¿ä¸Šä¸‹æ–‡æ— æ•ˆï¼ˆæ¸…ç†ï¼‰
- **å‚æ•°ï¼š** æ— 
- **è¿”å›ï¼š** `void`
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** å¯èƒ½ç­‰åŒäº `gpuf_release_context`

#### `context.isModelLoaded`
- **ä½ç½®ï¼š** `ios/PocketPal/AppIntents/LlamaContextWrapper.mm:40`
- **ç”¨é€”ï¼š** æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
- **ç±»å‹ï¼š** `boolean`ï¼ˆå±æ€§ï¼‰
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** âŒ **ç¼ºå¤±** - éœ€è¦æä¾› `gpuf_is_model_loaded(context)`

### 3. Context å±æ€§

#### `context.model`
- **ä½ç½®ï¼š** å¤šå¤„ä½¿ç”¨
- **ç”¨é€”ï¼š** è®¿é—®æ¨¡å‹ä¿¡æ¯
- **å±æ€§ï¼š**
  ```typescript
  {
    size: number,        // æ¨¡å‹å¤§å°
    nParams: number,     // å‚æ•°æ•°é‡
    desc: string,        // æ¨¡å‹æè¿°
    // ... æ›´å¤šå±æ€§
  }
  ```
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** âŒ **ç¼ºå¤±** - éœ€è¦æä¾› `gpuf_get_model_info(context)`

#### `context.id`
- **ä½ç½®ï¼š** `src/hooks/useChatSession.ts:131`
- **ç”¨é€”ï¼š** ä¸Šä¸‹æ–‡ ID
- **ç±»å‹ï¼š** `number`
- **å¯¹åº”åç«¯æ–¹æ³•ï¼š** å¯èƒ½éœ€è¦ `gpuf_get_context_id(context)`

## ğŸ“Š æ–¹æ³•å¯¹æ¯”æ€»ç»“

| åŠŸèƒ½ | åç«¯æä¾› | é¡¹ç›®éœ€è¦ | çŠ¶æ€ |
|------|---------|---------|------|
| åˆå§‹åŒ– SDK | âœ… `gpuf_init` | âœ… | âœ… å·²æä¾› |
| æ¸…ç† SDK | âœ… `gpuf_cleanup` | âœ… | âœ… å·²æä¾› |
| åŠ è½½æ¨¡å‹ | âœ… `gpuf_load_model` | âœ… | âœ… å·²æä¾› |
| åˆ›å»ºä¸Šä¸‹æ–‡ | âœ… `gpuf_create_context` | âœ… | âœ… å·²æä¾› |
| ç”Ÿæˆæ–‡æœ¬ | âœ… `gpuf_generate_with_sampling` | âœ… `completion` | âš ï¸ éœ€è¦å¢å¼º |
| åœæ­¢ç”Ÿæˆ | âŒ | âœ… `stopCompletion` | âŒ **ç¼ºå¤±** |
| è·å–æ¨¡å‹ä¿¡æ¯ | âŒ | âœ… `loadLlamaModelInfo` | âŒ **ç¼ºå¤±** |
| æ ¼å¼åŒ–èŠå¤© | âŒ | âœ… `getFormattedChat` | âŒ **ç¼ºå¤±** |
| å¤šæ¨¡æ€åˆå§‹åŒ– | âŒ | âœ… `initMultimodal` | âŒ **ç¼ºå¤±** |
| æ£€æŸ¥å¤šæ¨¡æ€ | âŒ | âœ… `isMultimodalEnabled` | âŒ **ç¼ºå¤±** |
| é‡Šæ”¾å¤šæ¨¡æ€ | âŒ | âœ… `releaseMultimodal` | âŒ **ç¼ºå¤±** |
| é‡Šæ”¾ä¸Šä¸‹æ–‡ | âŒ | âœ… `release` | âŒ **ç¼ºå¤±** |
| æ€§èƒ½åŸºå‡†æµ‹è¯• | âŒ | âœ… `bench` | âŒ **ç¼ºå¤±** |
| ä¿å­˜ä¼šè¯ | âŒ | âœ… `saveSession` | âŒ **ç¼ºå¤±** |
| åŠ è½½ä¼šè¯ | âŒ | âœ… `loadSession` | âŒ **ç¼ºå¤±** |
| æ£€æŸ¥æ¨¡å‹åŠ è½½ | âŒ | âœ… `isModelLoaded` | âŒ **ç¼ºå¤±** |
| è·å–æ¨¡å‹å±æ€§ | âŒ | âœ… `model` å±æ€§ | âŒ **ç¼ºå¤±** |

## ğŸš¨ éœ€è¦åç«¯æä¾›çš„æ–¹æ³•

### é«˜ä¼˜å…ˆçº§ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰

1. **`gpuf_stop_generation(context)`**
   - åœæ­¢æ­£åœ¨è¿›è¡Œçš„æ–‡æœ¬ç”Ÿæˆ
   - å‚æ•°ï¼š`llama_context* ctx`
   - è¿”å›ï¼š`int` (0 = æˆåŠŸ)

2. **`gpuf_get_model_info(model_path)`**
   - è·å–æ¨¡å‹ä¿¡æ¯ï¼ˆä¸åŠ è½½å®Œæ•´æ¨¡å‹ï¼‰
   - å‚æ•°ï¼š`const char* model_path`
   - è¿”å›ï¼š`ModelInfo*` æˆ– JSON å­—ç¬¦ä¸²
   - éœ€è¦åŒ…å«ï¼šæ–‡ä»¶ç±»å‹ã€å‚æ•°æ•°é‡ã€ä¸Šä¸‹æ–‡é•¿åº¦ç­‰

3. **`gpuf_release_context(context)`**
   - é‡Šæ”¾ä¸Šä¸‹æ–‡èµ„æº
   - å‚æ•°ï¼š`llama_context* ctx`
   - è¿”å›ï¼š`int` (0 = æˆåŠŸ)

4. **`gpuf_is_model_loaded(context)`**
   - æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
   - å‚æ•°ï¼š`llama_context* ctx`
   - è¿”å›ï¼š`int` (1 = å·²åŠ è½½, 0 = æœªåŠ è½½)

### ä¸­ä¼˜å…ˆçº§ï¼ˆé‡è¦åŠŸèƒ½ï¼‰

5. **`gpuf_format_chat(context, messages, template)`**
   - ä½¿ç”¨èŠå¤©æ¨¡æ¿æ ¼å¼åŒ–æ¶ˆæ¯
   - å‚æ•°ï¼š
     - `llama_context* ctx`
     - `const char* messages` (JSON æ ¼å¼)
     - `const char* template` (å¯é€‰ï¼ŒJinja2 æ¨¡æ¿)
   - è¿”å›ï¼š`char*` (æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²)

6. **`gpuf_get_model_metadata(context)`**
   - è·å–æ¨¡å‹å…ƒæ•°æ®
   - å‚æ•°ï¼š`llama_context* ctx`
   - è¿”å›ï¼š`char*` (JSON æ ¼å¼ï¼ŒåŒ…å« size, nParams, desc ç­‰)

### ä½ä¼˜å…ˆçº§ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰

7. **`gpuf_init_multimodal(context, mmproj_path, use_gpu)`**
   - åˆå§‹åŒ–å¤šæ¨¡æ€æ”¯æŒ
   - å‚æ•°ï¼š
     - `llama_context* ctx`
     - `const char* mmproj_path`
     - `int use_gpu`
   - è¿”å›ï¼š`int` (1 = æˆåŠŸ, 0 = å¤±è´¥)

8. **`gpuf_is_multimodal_enabled(context)`**
   - æ£€æŸ¥å¤šæ¨¡æ€æ˜¯å¦å¯ç”¨
   - å‚æ•°ï¼š`llama_context* ctx`
   - è¿”å›ï¼š`int` (1 = å¯ç”¨, 0 = æœªå¯ç”¨)

9. **`gpuf_release_multimodal(context)`**
   - é‡Šæ”¾å¤šæ¨¡æ€èµ„æº
   - å‚æ•°ï¼š`llama_context* ctx`
   - è¿”å›ï¼š`int` (0 = æˆåŠŸ)

10. **`gpuf_save_session(context, path, size)`**
    - ä¿å­˜ä¼šè¯ç¼“å­˜
    - å‚æ•°ï¼š
      - `llama_context* ctx`
      - `const char* path`
      - `int size` (-1 è¡¨ç¤ºå…¨éƒ¨)
    - è¿”å›ï¼š`int` (ä¿å­˜çš„ token æ•°é‡)

11. **`gpuf_load_session(context, path)`**
    - åŠ è½½ä¼šè¯ç¼“å­˜
    - å‚æ•°ï¼š
      - `llama_context* ctx`
      - `const char* path`
    - è¿”å›ï¼š`int` (åŠ è½½çš„ token æ•°é‡)

12. **`gpuf_bench(context, pp, tg, pl, nr)`**
    - è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
    - å‚æ•°ï¼š
      - `llama_context* ctx`
      - `int pp` (prompt processing)
      - `int tg` (token generation)
      - `int pl` (prompt length)
      - `int nr` (number of runs)
    - è¿”å›ï¼š`char*` (JSON æ ¼å¼ï¼ŒåŒ…å« speedPp, speedTg)

## ğŸ”§ éœ€è¦å¢å¼ºçš„ç°æœ‰æ–¹æ³•

### `gpuf_generate_with_sampling`

å½“å‰æ–¹æ³•ç­¾åï¼š
```c
int gpuf_generate_with_sampling(
    llama_model* model,
    llama_context* ctx,
    const char* prompt,
    int max_tokens,
    float temperature,
    int top_k,
    float top_p,
    float repeat_penalty,
    LlamaToken* token_buffer,
    int token_buffer_size,
    char* output,
    int output_len
);
```

**éœ€è¦å¢å¼ºçš„åŠŸèƒ½ï¼š**

1. **æµå¼è¾“å‡ºæ”¯æŒ**
   - æ·»åŠ å›è°ƒå‡½æ•°å‚æ•°ï¼š`void (*on_token)(const char* token, void* user_data)`
   - å…è®¸å®æ—¶è¿”å›ç”Ÿæˆçš„ token

2. **æ›´å¤šé‡‡æ ·å‚æ•°**
   - `min_p` (æœ€å°æ¦‚ç‡)
   - `xtc_threshold` (XTC é˜ˆå€¼)
   - `xtc_probability` (XTC æ¦‚ç‡)
   - `typical_p` (å…¸å‹é‡‡æ ·)
   - `penalty_last_n` (æƒ©ç½šçª—å£)
   - `penalty_freq` (é¢‘ç‡æƒ©ç½š)
   - `penalty_present` (å­˜åœ¨æƒ©ç½š)
   - `mirostat` (Mirostat é‡‡æ ·)
   - `mirostat_tau` (Mirostat tau)
   - `mirostat_eta` (Mirostat eta)
   - `seed` (éšæœºç§å­)

3. **åœæ­¢è¯æ”¯æŒ**
   - æ·»åŠ å‚æ•°ï¼š`const char** stop_words, int stop_words_count`

4. **ç»“æ„åŒ–è¾“å‡ºæ”¯æŒ**
   - æ·»åŠ å‚æ•°ï¼š`const char* json_schema` (JSON Schema å­—ç¬¦ä¸²)

5. **æ¶ˆæ¯æ ¼å¼æ”¯æŒ**
   - æ”¯æŒ `messages` æ•°ç»„æ ¼å¼ï¼ˆä¸ä»…ä»…æ˜¯ prompt å­—ç¬¦ä¸²ï¼‰
   - æ”¯æŒå¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆæ–‡æœ¬ + å›¾åƒï¼‰

6. **è¿”å›æ›´å¤šä¿¡æ¯**
   - è¿”å›ç»“æ„ä½“åŒ…å«ï¼š`text`, `timings`, `tokens_generated` ç­‰

**å»ºè®®çš„æ–°ç­¾åï¼š**
```c
typedef struct {
    char* text;
    int tokens_generated;
    double time_to_first_token;
    double total_time;
} GenerationResult;

typedef void (*TokenCallback)(const char* token, void* user_data);

int gpuf_generate_with_sampling_v2(
    llama_context* ctx,
    const char* prompt_or_messages,  // JSON æ ¼å¼
    GenerationParams* params,         // åŒ…å«æ‰€æœ‰é‡‡æ ·å‚æ•°
    const char** stop_words,
    int stop_words_count,
    const char* json_schema,          // å¯é€‰ï¼Œç”¨äºç»“æ„åŒ–è¾“å‡º
    TokenCallback on_token,           // å¯é€‰ï¼Œæµå¼è¾“å‡ºå›è°ƒ
    void* user_data,                  // å›è°ƒç”¨æˆ·æ•°æ®
    GenerationResult* result           // è¾“å‡ºç»“æœ
);
```

## ğŸ“ æ€»ç»“

### å¿…é¡»æä¾›çš„æ–¹æ³•ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰
1. âœ… `gpuf_stop_generation` - åœæ­¢ç”Ÿæˆ
2. âœ… `gpuf_get_model_info` - è·å–æ¨¡å‹ä¿¡æ¯
3. âœ… `gpuf_release_context` - é‡Šæ”¾ä¸Šä¸‹æ–‡
4. âœ… `gpuf_is_model_loaded` - æ£€æŸ¥æ¨¡å‹åŠ è½½çŠ¶æ€

### å»ºè®®æä¾›çš„æ–¹æ³•ï¼ˆé‡è¦åŠŸèƒ½ï¼‰
5. âœ… `gpuf_format_chat` - æ ¼å¼åŒ–èŠå¤©
6. âœ… `gpuf_get_model_metadata` - è·å–æ¨¡å‹å…ƒæ•°æ®

### å¯é€‰æä¾›çš„æ–¹æ³•ï¼ˆå¢å¼ºåŠŸèƒ½ï¼‰
7. âœ… `gpuf_init_multimodal` - å¤šæ¨¡æ€åˆå§‹åŒ–
8. âœ… `gpuf_is_multimodal_enabled` - æ£€æŸ¥å¤šæ¨¡æ€
9. âœ… `gpuf_release_multimodal` - é‡Šæ”¾å¤šæ¨¡æ€
10. âœ… `gpuf_save_session` - ä¿å­˜ä¼šè¯
11. âœ… `gpuf_load_session` - åŠ è½½ä¼šè¯
12. âœ… `gpuf_bench` - æ€§èƒ½åŸºå‡†æµ‹è¯•

### éœ€è¦å¢å¼ºçš„ç°æœ‰æ–¹æ³•
- âš ï¸ `gpuf_generate_with_sampling` - éœ€è¦æ”¯æŒæµå¼è¾“å‡ºã€æ›´å¤šå‚æ•°ã€æ¶ˆæ¯æ ¼å¼ç­‰

